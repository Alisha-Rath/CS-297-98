<div class="center">
<h1>Case Data Preparation</h1>
</div>
<h2><p><b>Description:</b></p></h2>
<p>This deliverable focuses on finding, analyzing, and preparing datasets suitable for predicting legal case outcomes using machine learning models. The goal was to identify a dataset that could be effectively used for training and evaluating models for legal decision prediction tasks. I reviewed multiple sources and ultimately selected the most appropriate dataset.</p>

<h2><p><b>Steps Followed:</b></p></h2>
<p>Here is a breakdown of the steps I took during the data preparation phase:</p>

<h3>Step 1: Researching Available Datasets</h3>
<p>I explored various online repositories and resources to find datasets that could be used for predicting court case outcomes. Key sources considered included Kaggle, GitHub repositories, and other data-sharing platforms:</p>
<ul>
    <li><strong>Kaggle - Supreme Court Judgment Prediction:</strong> A dataset containing 3,304 cases from 1955 to 2021, with details like case identifiers, facts, and judgment outcomes. The dataset is designed to predict legal judgments using Natural Language Processing (NLP) techniques. It was selected for its comprehensive data and well-structured format. <a href="https://www.kaggle.com/datasets/deepcontractor/supreme-court-judgment-prediction">View Dataset</a></li>
    <li><strong>GitHub - Oyez Decision Prediction:</strong> This dataset from a GitHub project includes details of case facts and outcomes, focusing on NLP-based legal predictions. It provided a rich textual dataset but was more limited in the scope of cases and metadata. <a href="https://github.com/smitp415/CSCI_544_Final_Project/blob/main/oyez_decision_prediction.ipynb">View Dataset</a></li>
    <li><strong>Hugging Face - Swiss Judgment Prediction:</strong> A multilingual dataset with 85,000 cases from the Federal Supreme Court of Switzerland. This dataset was useful for understanding cross-linguistic judgment prediction but required significant preprocessing for adaptation. <a href="https://huggingface.co/datasets/rcds/swiss_judgment_prediction">View Dataset</a></li>
</ul>

<h3>Step 2: Dataset Comparison</h3>
<p>To ensure the best choice for model training, I compared the three datasets based on their features, size, linguistic diversity, and suitability for the task. The table below summarizes the differences:</p>
<table style="border-collapse: collapse; width: 100%;">
    <thead>
        <tr>
            <th style="border: 1px solid #000; padding: 8px;">Dataset Name</th>
            <th style="border: 1px solid #000; padding: 8px;">Source</th>
            <th style="border: 1px solid #000; padding: 8px;">Cases</th>
            <th style="border: 1px solid #000; padding: 8px;">Language(s)</th>
            <th style="border: 1px solid #000; padding: 8px;">Key Features</th>
            <th style="border: 1px solid #000; padding: 8px;">Advantages</th>
            <th style="border: 1px solid #000; padding: 8px;">Disadvantages</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="border: 1px solid #000; padding: 8px;"><strong>Supreme Court Judgment Prediction</strong></td>
            <td style="border: 1px solid #000; padding: 8px;">Kaggle</td>
            <td style="border: 1px solid #000; padding: 8px;">3,304</td>
            <td style="border: 1px solid #000; padding: 8px;">English</td>
            <td style="border: 1px solid #000; padding: 8px;">Case facts, judgment outcomes</td>
            <td style="border: 1px solid #000; padding: 8px;">Well-structured, comprehensive, and focused on US cases</td>
            <td style="border: 1px solid #000; padding: 8px;">Limited to US cases</td>
        </tr>
        <tr>
            <td style="border: 1px solid #000; padding: 8px;"><strong>Oyez Decision Prediction</strong></td>
            <td style="border: 1px solid #000; padding: 8px;">GitHub</td>
            <td style="border: 1px solid #000; padding: 8px;">~1,000</td>
            <td style="border: 1px solid #000; padding: 8px;">English</td>
            <td style="border: 1px solid #000; padding: 8px;">Detailed textual descriptions, outcomes</td>
            <td style="border: 1px solid #000; padding: 8px;">Rich textual data for NLP</td>
            <td style="border: 1px solid #000; padding: 8px;">Smaller scope and fewer data points</td>
        </tr>
        <tr>
            <td style="border: 1px solid #000; padding: 8px;"><strong>Swiss Judgment Prediction</strong></td>
            <td style="border: 1px solid #000; padding: 8px;">Hugging Face</td>
            <td style="border: 1px solid #000; padding: 8px;">85,000</td>
            <td style="border: 1px solid #000; padding: 8px;">German, French, Italian</td>
            <td style="border: 1px solid #000; padding: 8px;">Multilingual facts, approval/dismissal outcomes</td>
            <td style="border: 1px solid #000; padding: 8px;">Large size, multilingual diversity</td>
            <td style="border: 1px solid #000; padding: 8px;">Requires significant preprocessing and adaptation for English-only models</td>
        </tr>
    </tbody>
</table>


<h3>Step 3: Dataset Selection</h3>
<p>After comparing the datasets based on features, size, and compatibility with the project requirements, I selected the <strong>Supreme Court Judgment Prediction dataset</strong> from Kaggle. The primary reasons for this choice were:</p>
<ul>
    <li><strong>Rich Metadata:</strong> Includes unique case identifiers, facts, and judgments, providing a good basis for predictive modeling.</li>
    <li><strong>Historical Coverage:</strong> Spans cases from 1955 to 2021, offering a broad view of legal precedents and outcomes.</li>
    <li><strong>Ease of Access:</strong> Available in a structured format that made it easier to preprocess and integrate with machine learning models.</li>
</ul>


<h2><p><b>Use of the Supreme Court Dataset</p></b> </h2>
<p>I reviewed a project titled "<strong>Machine Court Justice: Predicting Supreme Court Outcomes</strong>," which utilized the Kaggle Supreme Court dataset to train and evaluate a logistic regression model for outcome prediction. The project's use of this dataset allowed for analysis of case characteristics, such as issue areas and voting patterns. The model achieved a predictive accuracy of 60%, illustrating challenges like dataset imbalance and the complexity of interpreting legal texts. </p>

<h2><p></b>Dataset Analysis and Cleaning</p></b></h2>
<p>The dataset contained case identifiers, textual descriptions of the facts, and corresponding judgment labels (1 for first_party_wins and 0 for first_party_loses).

<h3>Code Snippet</h3>
<p>1. Below is an image showing the code snippet for loading the dataset:</p>
<img src="load.png" alt="Code snippet for for loading the dataset" style="width:50%;">

<p>2. Below is an image showing the code snippet for preprocessing dataset:</p>
<img src="preprocess.png" alt="Code snippet for preprocessing dataset" style="width:50%;">

<p>3. Below is an image showing the code snippet for splitting the dataset to train and test:</p>
<img src="split.png" alt="Code snippet for splitting the dataset to train and test" style="width:50%;">


<h2><p><b>Insights Gained</b></p></h2>
<p>This phase helped me understand the importance of selecting the right dataset for model training, as well as the challenges associated with legal text data. I gained insights into how well-structured datasets can significantly enhance the modeling process and the value of historical context in legal predictions.</p>

<h2><p><b>Next Steps</b></p></h2>
<p>Moving forward, I plan to apply the insights gained from this analysis to optimize the preprocessing steps for the Supreme Court dataset. Additionally, I aim to explore more advanced machine learning techniques and evaluate their effectiveness in improving prediction accuracy for legal case outcomes.</p>

<h2><p><b>Presentation links:</b></p></h2>
<p>You can see the PDF on the left side of the page too:</p>
<p><a href="Machine_Court_Justice_Presentation.pdf">Paper_Using_Dataset - PDF</a> </p>

